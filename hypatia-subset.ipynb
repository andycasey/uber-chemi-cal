{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.table import Table\n",
    "from glob import glob\n",
    "\n",
    "import stan_utils as stan\n",
    "from mpl_utils import (mpl_style, common_limits)\n",
    "\n",
    "plt.style.use(mpl_style)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "survey_data_paths = glob(\"data/*.csv\")\n",
    "survey_data = [Table.read(dp) for dp in survey_data_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Adibekyan12-all-renorm.csv ('HIP', 'Star', 'Teff', 'logg', 'FeH', 'NaH', 'MgH', 'AlH', 'SiH', 'CaH', 'ScIH', 'ScIIH', 'TiIH', 'TiIIH', 'VH', 'CrIH', 'CrIIH', 'MnH', 'CoH', 'NiH')\n",
      "data/Bensby14-all-renorm.csv ('HIP', 'Teff', 'logg', 'FeH', 'OH', 'NaH', 'MgH', 'AlH', 'SiH', 'CaH', 'TiH', 'CrH', 'NiH', 'ZnH', 'YH', 'BaH')\n",
      "data/Valenti05-all-renorm.csv ('HIP', 'HD', 'Teff', 'logg', 'NaH', 'SiH', 'TiH', 'FeH', 'NiH')\n"
     ]
    }
   ],
   "source": [
    "for dp, d in zip(survey_data_paths, survey_data):\n",
    "    print(dp, d.dtype.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_identifier = \"HIP\"\n",
    "label_names = (\"Teff\", \"logg\", \"FeH\", \"MgH\", \"SiH\", \"NaH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate the data arrays\n",
    "unique_hip_names = np.sort(np.unique(np.hstack([d[\"HIP\"] for d in survey_data])))\n",
    "N = unique_hip_names.size\n",
    "M = len(survey_data)\n",
    "D = len(label_names)\n",
    "\n",
    "y = np.nan * np.ones((N, M, D), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m, data in enumerate(survey_data):\n",
    "    for i, star in enumerate(data):\n",
    "        n = np.where(star[label_identifier] == unique_hip_names)[0][0]\n",
    "        y[n, m, :] = np.array([(star[ln] if ln in star.dtype.names else np.nan) \\\n",
    "                               for ln in label_names])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set bad abundances as nans\n",
    "for d, label_name in enumerate(label_names):\n",
    "    if label_name not in (\"Teff\", \"logg\"):\n",
    "        y[:, :, d][(y[:, :, d] >= 90)] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teff: (4556.0 to 7212.0), mean/median/std: 5667.9/5726.0/423.6 (2718 finite)\n",
      "logg: (2.7 to 5.1), mean/median/std: 4.3/4.4/0.2 (2718 finite)\n",
      "FeH: (-2.6 to 0.6), mean/median/std: -0.1/-0.1/0.3 (2718 finite)\n",
      "MgH: (-1.4 to 0.6), mean/median/std: 0.0/0.0/0.2 (1715 finite)\n",
      "SiH: (-1.6 to 0.7), mean/median/std: -0.0/0.0/0.2 (2714 finite)\n",
      "NaH: (-2.0 to 1.0), mean/median/std: -0.0/0.0/0.3 (2710 finite)\n"
     ]
    }
   ],
   "source": [
    "# checks\n",
    "for d, label_name in enumerate(label_names):\n",
    "    _ = y[:, :, d]\n",
    "    print(\"{0}: ({1:.1f} to {2:.1f}), mean/median/std: {3:.1f}/{4:.1f}/{5:.1f} ({6:.0f} finite)\".format(\n",
    "          label_name, np.nanmin(_), np.nanmax(_), \n",
    "          np.nanmean(_), np.nanmedian(_), np.nanstd(_),\n",
    "          np.sum(np.isfinite(_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arc/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "# Create an additive variance array to account for missing data.\n",
    "def de_gapify_data(y, additional_variance=1e8):\n",
    "    \"\"\"\n",
    "    Fill NaNs in the label vectors with the mean values of other\n",
    "    labels. No structure is assumed for the missing labels (e.g.,\n",
    "    some labels could be missing from some surveys, but not all).\n",
    "    \n",
    "    :param y:\n",
    "        The label vector, where NaNs represent missing data.\n",
    "    \n",
    "    :param additional_variance: [optional]\n",
    "        The variance to add for missing data.\n",
    "    \"\"\"\n",
    "    \n",
    "    N, M, D = y.shape\n",
    "    missing = ~np.isfinite(y)\n",
    "    mean_stellar_labels = np.nanmean(y, axis=1)\n",
    "    mean_labels = np.nanmean(y.reshape((-1, D)), axis=0)\n",
    "\n",
    "    for d in range(D):\n",
    "        mean_stellar_labels[:, d][~np.isfinite(mean_stellar_labels[:, d])] = mean_labels[d]\n",
    "\n",
    "    y_full_rank = np.copy(y)\n",
    "    variance = np.zeros_like(y)\n",
    "    for m in range(M):\n",
    "        y_full_rank[:, m, :][missing[:, m, :]] = mean_stellar_labels[missing[:, m, :]]\n",
    "        variance[:, m, :][missing[:, m, :]] = 1.0\n",
    "        assert np.all(np.isfinite(y_full_rank[:, m, :]))\n",
    "\n",
    "    variance *= additional_variance\n",
    "\n",
    "    assert np.all(np.isfinite(y_full_rank))\n",
    "    return (y_full_rank, variance)\n",
    "\n",
    "y_full_rank, extra_variance = de_gapify_data(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using pre-compiled model from model-missing-data.stan.cached\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/*\n",
      "  Latent factor model for chemical abundances from multiple studies, allowing\n",
      "  for missing data.\n",
      "*/\n",
      "\n",
      "data {\n",
      "  int<lower=1> N; // number of stars\n",
      "  int<lower=1> D; // dimensionality of the data (number of labels)\n",
      "  int<lower=1> M; // number of surveys (or studies)\n",
      "  vector[D] y[N, M]; // the labels as reported by various surveys.\n",
      "  vector<lower=0>[D] scales; // fixed relative scales for latent factors\n",
      "  vector[D] y_additive_variance[N, M]; // variance to add for missing data.\n",
      "}\n",
      "\n",
      "transformed data {\n",
      "  vector[D] mu; // the mean of the data in each dimension\n",
      "  int<lower=1> Q; // the number of non-zero lower-triangular entries that we\n",
      "                  // need for the decomposoition of our theta matrix\n",
      "  Q = M * choose(D, 2);\n",
      "\n",
      "  // TODO: Stop assuming that the user is not an idiot\n",
      "  mu = rep_vector(0.0, D);\n",
      "}\n",
      "\n",
      "parameters {\n",
      "  vector[D] X[N]; // latent factors for each star\n",
      "  vector<lower=0>[M] phi[D]; // variance on survey labels\n",
      "\n",
      "  vector[Q] L_lower_triangular; // lower triangular entries of the decomposition\n",
      "                                // of the  theta matrix\n",
      "  vector<lower=0>[M] L_diag[D]; // diagonal entries of the decomposition of the \n",
      "                                // theta matrix\n",
      "}\n",
      "\n",
      "transformed parameters {\n",
      "  cholesky_factor_cov[D, D] L[M];\n",
      "  matrix[D, D] theta[M];\n",
      "  {\n",
      "    int q = 0;\n",
      "\n",
      "    for (m in 1:M)\n",
      "      for (i in 1:D)\n",
      "        for (j in (i + 1):D) \n",
      "          L[m, i, j] = 0.0;\n",
      "\n",
      "    for (m in 1:M) {\n",
      "      for (i in 1:D) {\n",
      "        L[m, i, i] = L_diag[i, m];\n",
      "        for (j in (i + 1):D) {\n",
      "          q = q + 1;\n",
      "          L[m, j, i] = L_lower_triangular[q];\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "\n",
      "    for (m in 1:M)\n",
      "      theta[m] = multiply_lower_tri_self_transpose(L[m]);\n",
      "  }\n",
      "}\n",
      "\n",
      "model {\n",
      "\n",
      "  // Place priors on various properties.\n",
      "  for (d in 1:D) {\n",
      "    X[:, d] ~ normal(rep_vector(0, N), rep_vector(scales[d], N));\n",
      "    phi[d] ~ normal(rep_vector(0, M), rep_vector(1, M));\n",
      "\n",
      "    // TODO: Should we be placing an inverted Wishart prior or something on this\n",
      "    //       shit?\n",
      "    //L_lower_triangular\n",
      "\n",
      "    // TODO: revisit this prior\n",
      "    L_diag[d] ~ normal(rep_vector(1, M), rep_vector(0.1, M));\n",
      "  }\n",
      "\n",
      "  for (n in 1:N) \n",
      "    for (m in 1:M)\n",
      "      y[n, m, :] ~ normal(to_row_vector(X[n]) * theta[m], \n",
      "                          sqrt(to_vector(phi[:, m]) + y_additive_variance[n, m, :]));\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = stan.read_model(\"model-missing-data.stan\")\n",
    "print(model.model_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the model.\n",
    "mu = np.mean(y_full_rank.reshape((-1, D)), axis=0)\n",
    "scales = np.std(y_full_rank.reshape((-1, D)), axis=0)\n",
    "\n",
    "data = dict(N=N, M=M, D=D, scales=scales, \n",
    "            y=y_full_rank - mu, y_additive_variance=extra_variance)\n",
    "\n",
    "op_kwds = dict(\n",
    "    data=data, \n",
    "    iter=100000, \n",
    "    tol_obj=7./3 - 4./3 - 1, # machine precision\n",
    "    tol_grad=7./3 - 4./3 - 1, # machine precision\n",
    "    tol_rel_grad=1e3,\n",
    "    tol_rel_obj=1e4\n",
    ")\n",
    "\n",
    "p_opt = model.optimizing(**op_kwds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NFI whether we have optimized to something sensible or not yet,.....\n",
    "# \"an exercise for the reader\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3)",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
